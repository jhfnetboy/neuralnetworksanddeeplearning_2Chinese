关于本书：
	 
+ 神经网络(算法框架)是迄今为止已发明的最优美的编程范本(范式)之一。在既有的编程方式中,我们告诉电脑如何去做，把大的难题切分为许多电脑可执行的、精确定义的任务。相对而言，在神经网络中我们不会告诉电脑如何解决(我们)的问题，取而代之的是，它从观察数据中学习，亲手搞清楚自己的解决方案。

+ 自动化学习听起来很有前途。但是，直到2006年，除了一些特定问题领域，我们还不知道如何训练神经网络如何超越更多的传统途径。直到2006年一个所谓的深度神经网络学习技术的发现。这项技术现在叫深度学习。它们已经得到了进一步发展，今天深度神经网络和深度学习在计算机视觉、语音识别和自然语言处理许多重要的问题突出表现。已被公司如谷歌，微软和Facebook展开大规模的应用。

+ 这本书的目的是帮助你掌握神经网络，包括深度学习现代技术的核心概念。通过这本书，你就可以通过你的编码，使用神经网络和深度学习来解决复杂的模式识别问题。你将为使用神经网络和深度学习来攻克你自己的设计规划问题，奠定扎实的基础。

+ 一种面向原理的方法

+ 本书的一个根本信念是，应该更好地获得对神经网络和深度学习核心原理扎实的理解，而不是在一个长长清淡基础上的模糊理解。如果你已经理解核心思想很好了，你可以迅速了解其他新材料。在编程语言方面，把它认为是掌握一门新语言的核心语法，库和数据结构。你可能仍然只是“知道”的语言总体的一小部分 - 许多语言都有巨大的标准库 - 但新库和数据结构可以快速，容易地理解。

+ 这意味着，本书显然不是在教你如何使用一些特定的神经网络开发库教程。如果你主要是想了解关于某开发库的开发方式，那请不要读这本书！您可以通过教程和文档来学习你想了解的开发库和具体开发工作。但请注意：虽然这有一个直接解决问题的回报，如果你想了解在神经网络到底发生了什么，如果你想要真正的见解，那从现在开始，仍将要有些年头，那么只是学习一些热点的开发库是不够的。你需要了解的经久的，持续的，关于神经网络如何工作的见解。正所谓技术来，技术去，但洞察力是永恒。

+ 一个实用的方法

通过攻克一个具体的问题：教会计算机能够识别手写体数字的问题，我们将会学习到神经网络和深度学习背后的核心原理。这个问题使用常规方法来编程来解决是非常困难。然而，正如我们看到的，它可以通过一个简单的神经网络，被很好的解决，只需几十行代码，并没有用到特别的开发库。更重要的是，我们将通过多次迭代改进方案，逐步纳入有关神经网络和深度学习越来越多的核心思想。

这个有效的方法意味着你需要一些编程经验来读这本书。但你并不需要成为一个专业的程序员。我已经用Python编写了代码（2.7版），其中，即使你不用Python编写程序，那也应该很容易，只需一点点努力理解。通过这本书的过程，我们将开发一个小神经网络库，您可以用来试验，然后建立理解。所有的代码可以在这里下载。一旦你完成这本书，或者你读它时，你可以轻松地拿起来，一个在生产中使用的功能更加完善的神经网络库。

与此相关，数​​学要求读的书是温和的。在大多数章节都有一些数学，但它通常只是初等代数和功能图，我希望大多数读者都会处理好。我偶尔使用更先进的数学，但有结构性的材料，如果一些数学细节迷惑你​，​这样就可以跟随查找。使用数学较重的一章是第2章，这需要一点点多变量微积分和线性代数。如果这些不熟悉，第2章我开始对如何导航数学进行讨论。如果你发现它真的很艰难的事，你可以直接跳过这一章的主要总结。在任何情况下，没有必要在一开始就担心这个。

对一本书来说，既为面向原则，又强调动手性，这是罕见的。但我相信你会学到最好的，如果我们建立了神经网络的基本思想。我们将开发活的代码，不只是抽象的理论，代码，您可以探索和扩展。这样，你就会明白基本面，无论是在理论和实践，并将很好地进一步增加你的知识。


What this book is about?

Neural networks are one of the most beautiful programming paradigms ever invented. In the conventional approach to programming, we tell the computer what to do, breaking big problems up into many small, precisely defined tasks that the computer can easily perform. By contrast, in a neural network we don't tell the computer how to solve our problem. Instead, it learns from observational data, figuring out its own solution to the problem at hand.

Automatically learning from data sounds promising. However, until 2006 we didn't know how to train neural networks to surpass more traditional approaches, except for a few specialized problems. What changed in 2006 was the discovery of techniques for learning in so-called deep neural networks. These techniques are now known as deep learning. They've been developed further, and today deep neural networks and deep learning achieve outstanding performance on many important problems in computer vision, speech recognition, and natural language processing. They're being deployed on a large scale by companies such as Google, Microsoft, and Facebook.

The purpose of this book is to help you master the core concepts of neural networks, including modern techniques for deep learning. After working through the book you will have written code that uses neural networks and deep learning to solve complex pattern recognition problems. And you will have a foundation to use neural networks and deep learning to attack problems of your own devising.

A principle-oriented approach

One conviction underlying the book is that it's better to obtain a solid understanding of the core principles of neural networks and deep learning, rather than a hazy understanding of a long laundry list of ideas. If you've understood the core ideas well, you can rapidly understand other new material. In programming language terms, think of it as mastering the core syntax, libraries and data structures of a new language. You may still only "know" a tiny fraction of the total language - many languages have enormous standard libraries - but new libraries and data structures can be understood quickly and easily.

This means the book is emphatically not a tutorial in how to use some particular neural network library. If you mostly want to learn your way around a library, don't read this book! Find the library you wish to learn, and work through the tutorials and documentation. But be warned. While this has an immediate problem-solving payoff, if you want to understand what's really going on in neural networks, if you want insights that will still be relevant years from now, then it's not enough just to learn some hot library. You need to understand the durable, lasting insights underlying how neural networks work. Technologies come and technologies go, but insight is forever.

A hands-on approach

We'll learn the core principles behind neural networks and deep learning by attacking a concrete problem: the problem of teaching a computer to recognize handwritten digits. This problem is extremely difficult to solve using the conventional approach to programming. And yet, as we'll see, it can be solved pretty well using a simple neural network, with just a few tens of lines of code, and no special libraries. What's more, we'll improve the program through many iterations, gradually incorporating more and more of the core ideas about neural networks and deep learning.

This hands-on approach means that you'll need some programming experience to read the book. But you don't need to be a professional programmer. I've written the code in Python (version 2.7), which, even if you don't program in Python, should be easy to understand with just a little effort. Through the course of the book we will develop a little neural network library, which you can use to experiment and to build understanding. All the code is available for download here. Once you've finished the book, or as you read it, you can easily pick up one of the more feature-complete neural network libraries intended for use in production.

On a related note, the mathematical requirements to read the book are modest. There is some mathematics in most chapters, but it's usually just elementary algebra and plots of functions, which I expect most readers will be okay with. I occasionally use more advanced mathematics, but have structured the material so you can follow even if some mathematical details elude you. The one chapter which uses heavier mathematics extensively is Chapter 2, which requires a little multivariable calculus and linear algebra. If those aren't familiar, I begin Chapter 2 with a discussion of how to navigate the mathematics. If you're finding it really heavy going, you can simply skip to the summary of the chapter's main results. In any case, there's no need to worry about this at the outset.

It's rare for a book to aim to be both principle-oriented and hands-on. But I believe you'll learn best if we build out the fundamental ideas of neural networks. We'll develop living code, not just abstract theory, code which you can explore and extend. This way you'll understand the fundamentals, both in theory and practice, and be well set to add further to your knowledge.